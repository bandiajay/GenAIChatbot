# -*- coding: utf-8 -*-
"""GPT3_Chatbot.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10noPKlQdM8JvzOm5OHOAwp0LKBrZgP-Y
"""



import textwrap
import os
from langchain.document_loaders import TextLoader
os.environ["HUGGINGFACEHUB_API_TOKEN"] = "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"

loader = TextLoader("data.txt",encoding = 'UTF-8')
document = loader.load()

print(document)

#preprocessing
def wrap_text_preserve_newlines(text, width=110):
    lines = text.split('\n')

    wrapped_lines = [textwrap.fill(line,width=width) for line in lines]

    wrapped_text = '\n'.join(wrapped_lines)

    return wrapped_text

print(wrap_text_preserve_newlines(str(document[0])))

#Text Splitting
from langchain.text_splitter import CharacterTextSplitter
text_splitter = CharacterTextSplitter(chunk_size = 1000, chunk_overlap = 0)

docs = text_splitter.split_documents(document)

print(docs[0])
print(len(docs))


#Embedding
#python -m pip install faiss-cpu
import faiss
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS

embeddings = HuggingFaceEmbeddings()
db = FAISS.from_documents(docs, embeddings)

query = "Tell me about the course overview?"

doc = db.similarity_search(query)

print(wrap_text_preserve_newlines(str(doc[0].page_content)))



from langchain.chains.question_answering import load_qa_chain
from langchain import HuggingFaceHub

llm = HuggingFaceHub(repo_id = "google/flan-t5-xxl",model_kwargs={"temperature":0.8, "max_length":512})

chain = load_qa_chain(llm, chain_type="stuff")

queryText = "who are the professors in ACS course?"
docsResult = db.similarity_search(queryText)

chain.run(input_documents = docsResult, question = queryText)

def genai_engine(query):
    # Run the chain with the query
    response = chain.run(input_documents=docsResult, question=query)
    return response


print(genai_engine("list all professors in ACS course?"))



queryText = "who is Ajay bandi?"
docsResult = db.similarity_search(queryText)

chain.run(input_documents = docsResult, question = queryText)

queryText = "who is Dr. Mark Chai here?"
docsResult = db.similarity_search(queryText)

chain.run(input_documents = docsResult, question = queryText)

queryText = "What is the tuition fee for the Master's in Computer Science program at Northwest Missouri State University?"
docsResult = db.similarity_search(queryText)

chain.run(input_documents = docsResult, question = queryText)

print(len(queryText))

doc_lengths = [len(doc.page_content.split()) for doc in docsResult]
print(f"Average document length: {sum(doc_lengths) / len(doc_lengths)}")


